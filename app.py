import streamlit as st
import requests
import xmltodict 
import urllib.parse 
import re  # HTML íƒœê·¸ ì œê±°ë¥¼ ìœ„í•œ ëª¨ë“ˆ

st.set_page_config(page_title="ê³ êµí•™ì ì œ ìë£Œ íƒìƒ‰", layout="centered")
st.title("ğŸ“š ì—ë“€ë„· ê³ êµí•™ì ì œ ìë£Œ ê²€ìƒ‰ê¸°")
st.write("ê¶ê¸ˆí•œ ê³ êµí•™ì ì œ ê´€ë ¨ ê³¼ëª©/í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•˜ê³  ê³µì‹ ìë£Œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# 1. API í‚¤ ë° ë„ë©”ì¸ ì„¤ì • (Streamlit Secretsì—ì„œ ê°€ì ¸ì˜´)
try:
    # 5ìë¦¬ ì¸ì¦í‚¤ (sno)
    SNO_KEY = st.secrets["KERIS_SNO_KEY"] 
    # Streamlit ë°°í¬ ì£¼ì†Œ ë˜ëŠ” localhost (svc_domain)
    SVC_DOMAIN = st.secrets.get("SVC_DOMAIN", "highschool-guide.streamlit.app") 
except KeyError:
    st.error("ğŸ”‘ KERIS_SNO_KEY ë˜ëŠ” SVC_DOMAINì´ Secretsì— ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()


# --- ì—ë“€ë„· API í˜¸ì¶œ í•¨ìˆ˜ ---
def search_keris_contents(query):
    # ë¬¸ì„œì— ëª…ì‹œëœ ìš”ì²­ URL
    url = "https://api.edunet.net/search/searchApi/search"
    
    # 2. ìš”ì²­ ë³€ìˆ˜(Request Parameters) ì„¤ì •
    params = {
        "collection": "cre_sys", # ê³ êµí•™ì ì œ(cre_sys) ê´€ë ¨ ìë£Œë§Œ ê²€ìƒ‰
        "sort": "r",             # ì •í™•ë„ìˆœ ì •ë ¬
        "searchType": "all",
        "pageNum": 1,
        "pageSize": 10,
        "sno": SNO_KEY,          # 5ìë¦¬ ì¸ì¦í‚¤
        "svc_version": "4.5",    # í˜„ì¬ ê²€ìƒ‰ ì—”ì§„ ë²„ì „
        "svc_domain": SVC_DOMAIN # ì ‘ì† ë„ë©”ì¸ ì •ë³´
    }
    
    # 3. kwd (ê²€ìƒ‰ì–´)ë¥¼ UTF-8 URL ì¸ì½”ë”©í•˜ì—¬ ì§ì ‘ URLì— í•©ì¹¨
    encoded_query = urllib.parse.quote(query, encoding='utf-8')
    full_url = f"{url}?kwd={encoded_query}&" + urllib.parse.urlencode(params)
    
    try:
        response = requests.get(full_url, timeout=10) 
        
        if response.status_code == 200 and 'xml' in response.headers.get('Content-Type', '').lower():
            # XMLì„ Python ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            return xmltodict.parse(response.content.decode('utf-8'))
        else:
            return {"error": f"HTTP ì˜¤ë¥˜ ë°œìƒ: {response.status_code}", "raw_content": response.text}
            
    except requests.exceptions.RequestException as e:
        return {"error": f"API í˜¸ì¶œ ì¤‘ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}"}

# --- UI ë° ê²€ìƒ‰ ì‹¤í–‰ ---
search_query = st.text_input("ê³ êµí•™ì ì œ ê´€ë ¨ í‚¤ì›Œë“œ (ì˜ˆ: ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ, 2025)", "2025")

if search_query:
    with st.spinner(f"ì—ë“€ë„· ê³µì‹ ìë£Œë¥¼ '{search_query}'ë¡œ ê²€ìƒ‰ ì¤‘..."):
        api_result = search_keris_contents(search_query)
    
    if "error" in api_result:
        st.error(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {api_result['error']}")
        with st.expander("ì›ë³¸ ì˜¤ë¥˜ ë©”ì‹œì§€ í™•ì¸"):
            st.write(api_result.get("raw_content", "ë¡œê·¸ ì—†ìŒ"))
    
    else:
        # 4. XML ë°ì´í„° êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ë°ì´í„° ì¶”ì¶œ
        try:
            # [ìˆ˜ì •ëœ ê²½ë¡œ ì‚¬ìš©] totalCountëŠ” 'search' ì§í•˜ìœ„ì— ìˆìŒ
            total_count = int(api_result['search']['totalCount'])
            
            st.success(f"âœ… ì´ {total_count}ê±´ì˜ ê³µì‹ ìë£Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            
            if total_count > 0:
                # dataListëŠ” 'totalResults'ì˜ ìì‹ ë…¸ë“œì— ìˆìœ¼ë©°, ê·¸ ì•ˆì— 'data'ê°€ ìˆìŒ
                data_list_node = api_result['search']['totalResults']['dataList']
                
                # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš°ì™€ ìˆì„ ê²½ìš°ë¥¼ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
                if data_list_node is not None and 'data' in data_list_node:
                    data_list = data_list_node['data']
                else:
                    data_list = [] 
                
                # ì‘ë‹µì´ ë‹¨ì¼ í•­ëª©ì¼ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                if not isinstance(data_list, list):
                    data_list = [data_list]

                if data_list:
                    for i, item in enumerate(data_list):
                        # 5. [í•µì‹¬ ìˆ˜ì •] HTML <b> íƒœê·¸ ì œê±°
                        raw_title = item.get('ttl', 'ì œëª© ì—†ìŒ')
                        clean_title = re.sub(r'</?b>', '', raw_title) # <b>ì™€ </b> íƒœê·¸ ëª¨ë‘ ì œê±°
                        
                        link = item.get('conts_link')
                        
                        st.markdown(f"### {i+1}. {clean_title}")
                        
                        category = item.get('srvc_clsf_nm_path', 'ë¶„ë¥˜ ì •ë³´ ì—†ìŒ')
                        st.caption(f"ë¶„ë¥˜: {category}")

                        st.write(item.get('cn', 'ìƒì„¸ ìš”ì•½ì´ ì—†ìŠµë‹ˆë‹¤.'))
                        
                        if link:
                            st.markdown(f"[ğŸ”— ì—ë“€ë„· ìƒì„¸ ìë£Œ ë°”ë¡œê°€ê¸°]({link})")
                        st.markdown("---")
            else:
                st.warning(f"'{search_query}' ê´€ë ¨ ìë£Œê°€ ì—ë“€ë„·ì—ì„œ ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
        except KeyError as e:
            st.error(f"âš ï¸ ë°ì´í„° êµ¬ì¡° ì˜¤ë¥˜: í•„ìˆ˜ í•„ë“œ '{e}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.write("ì—ë“€ë„·ì˜ XML ì‘ë‹µ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì˜ˆê¸°ì¹˜ ì•Šì€ ë°ì´í„°ê°€ ìˆ˜ì‹ ë˜ì—ˆìŠµë‹ˆë‹¤.")
            with st.expander("ì›ë³¸ ë¡œê·¸ í™•ì¸"):
                st.json(api_result)
        except Exception as e:
             st.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

st.divider()
st.caption("ì œê³µ: í•œêµ­êµìœ¡í•™ìˆ ì •ë³´ì›(KERIS) ì—ë“€ë„·Â·í‹°í´ë¦¬ì–´ API ê¸°ë°˜")
